{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b29c7bae",
      "metadata": {
        "id": "b29c7bae"
      },
      "source": [
        "\n",
        "# Clothes Image Classification  \n",
        "## Logistic Regression & MLP (PyTorch)\n",
        "\n",
        "### Objectives\n",
        "1. Predict clothing types using Logistic Regression\n",
        "2. Use 80:20 stratified split\n",
        "3. Evaluate using Macro F1-score\n",
        "4. Design MLP with 1, 2, 3 hidden layers\n",
        "5. Compare ReLU, Sigmoid, and Tanh activations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e27fa06",
      "metadata": {
        "id": "7e27fa06"
      },
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "89e30deb",
      "metadata": {
        "id": "89e30deb"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb7e2ec9",
      "metadata": {
        "id": "bb7e2ec9"
      },
      "source": [
        "## 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e396cf18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e396cf18",
        "outputId": "19f224bb-1567-463d-eae6-c1faab28bcc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ryanbadai/clothes-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.37G/1.37G [01:02<00:00, 23.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/ryanbadai/clothes-dataset/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:06<00:00, 73.45it/s]\n",
            "100%|██████████| 500/500 [00:07<00:00, 66.25it/s]\n",
            "100%|██████████| 500/500 [00:08<00:00, 57.59it/s]\n",
            "100%|██████████| 500/500 [00:06<00:00, 72.74it/s]\n",
            "100%|██████████| 500/500 [00:07<00:00, 65.55it/s]\n",
            "100%|██████████| 500/500 [00:07<00:00, 70.54it/s]\n",
            "100%|██████████| 500/500 [00:07<00:00, 67.33it/s]\n",
            "100%|██████████| 500/500 [00:07<00:00, 65.49it/s]\n",
            "100%|██████████| 500/500 [00:06<00:00, 73.81it/s]\n",
            "100%|██████████| 500/500 [00:07<00:00, 64.15it/s]\n",
            "100%|██████████| 500/500 [00:07<00:00, 65.54it/s]\n",
            "100%|██████████| 500/500 [00:06<00:00, 72.36it/s]\n",
            "100%|██████████| 500/500 [00:07<00:00, 65.52it/s]\n",
            "100%|██████████| 500/500 [00:06<00:00, 73.18it/s]\n",
            "100%|██████████| 500/500 [00:07<00:00, 64.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images shape: (7500, 64, 64, 3)\n",
            "Labels shape: (7500,)\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version from Kaggle\n",
        "path = kagglehub.dataset_download(\"ryanbadai/clothes-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "\n",
        "DATA_DIR = path\n",
        "IMAGE_SIZE = (64, 64)\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "base_classes_dir = os.path.join(DATA_DIR, \"Clothes_Dataset\")\n",
        "classes = sorted(os.listdir(base_classes_dir))\n",
        "\n",
        "for cls in classes:\n",
        "    cls_path = os.path.join(base_classes_dir, cls)\n",
        "\n",
        "    if os.path.isdir(cls_path):\n",
        "        for img_name in tqdm(os.listdir(cls_path)):\n",
        "            img_path = os.path.join(cls_path, img_name)\n",
        "\n",
        "            if os.path.isfile(img_path):\n",
        "                img = Image.open(img_path).convert(\"RGB\").resize(IMAGE_SIZE)\n",
        "                images.append(np.array(img))\n",
        "                labels.append(cls)\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"Images shape:\", images.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4271dc30",
      "metadata": {
        "id": "4271dc30"
      },
      "source": [
        "## 3. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7929a41c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7929a41c",
        "outputId": "50a8f244-b613-422d-b51c-c257faebb8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Macro F1: 0.31993924951945485\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X = images.reshape(len(images), -1)\n",
        "X = X / 255.0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "log_reg = LogisticRegression(\n",
        "    max_iter=200,\n",
        "    solver='lbfgs',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = log_reg.predict(X_test)\n",
        "f1_lr = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(\"Logistic Regression Macro F1:\", f1_lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a293e2a3",
      "metadata": {
        "id": "a293e2a3"
      },
      "source": [
        "## 4. PyTorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "98aca059",
      "metadata": {
        "id": "98aca059"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ClothesDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.label_map = {cls: i for i, cls in enumerate(sorted(set(labels)))}\n",
        "        self.labels = [self.label_map[l] for l in labels]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = torch.tensor(self.images[idx] / 255.0, dtype=torch.float32)\n",
        "        img = img.reshape(-1)\n",
        "        label = self.labels[idx]\n",
        "        return img, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac46031f",
      "metadata": {
        "id": "ac46031f"
      },
      "source": [
        "## 5. DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ae0aca83",
      "metadata": {
        "id": "ae0aca83"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_imgs, test_imgs, train_lbls, test_lbls = train_test_split(\n",
        "    images, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "train_ds = ClothesDataset(train_imgs, train_lbls)\n",
        "test_ds = ClothesDataset(test_imgs, test_lbls)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
        "\n",
        "input_dim = IMAGE_SIZE[0] * IMAGE_SIZE[1] * 3\n",
        "num_classes = len(set(labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30d9a88f",
      "metadata": {
        "id": "30d9a88f"
      },
      "source": [
        "## 6. MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9ae185bd",
      "metadata": {
        "id": "9ae185bd"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layers, activation, num_classes):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "\n",
        "        for h in hidden_layers:\n",
        "            layers.append(nn.Linear(prev, h))\n",
        "            if activation == 'relu':\n",
        "                layers.append(nn.ReLU())\n",
        "            elif activation == 'sigmoid':\n",
        "                layers.append(nn.Sigmoid())\n",
        "            elif activation == 'tanh':\n",
        "                layers.append(nn.Tanh())\n",
        "            prev = h\n",
        "\n",
        "        layers.append(nn.Linear(prev, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "065b7e40",
      "metadata": {
        "id": "065b7e40"
      },
      "source": [
        "## 7. Training & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3eaa4b6a",
      "metadata": {
        "id": "3eaa4b6a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_eval(model, train_loader, test_loader, epochs=15):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        model.train()\n",
        "        for X, y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(X), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            preds.extend(model(X).argmax(1).numpy())\n",
        "            trues.extend(y.numpy())\n",
        "\n",
        "    return f1_score(trues, preds, average='macro')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de34cde7",
      "metadata": {
        "id": "de34cde7"
      },
      "source": [
        "## 8. Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "21533668",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21533668",
        "outputId": "e58b5308-54ab-45c5-eed5-1b73ef8cd047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Hidden Layer relu Macro F1: 0.3242\n",
            "1 Hidden Layer sigmoid Macro F1: 0.1654\n",
            "1 Hidden Layer tanh Macro F1: 0.0354\n",
            "2 Hidden Layers relu Macro F1: 0.3696\n",
            "2 Hidden Layers sigmoid Macro F1: 0.1244\n",
            "2 Hidden Layers tanh Macro F1: 0.0201\n",
            "3 Hidden Layers relu Macro F1: 0.34\n",
            "3 Hidden Layers sigmoid Macro F1: 0.0777\n",
            "3 Hidden Layers tanh Macro F1: 0.0302\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('1 Hidden Layer', 'relu'): 0.3242,\n",
              " ('1 Hidden Layer', 'sigmoid'): 0.1654,\n",
              " ('1 Hidden Layer', 'tanh'): 0.0354,\n",
              " ('2 Hidden Layers', 'relu'): 0.3696,\n",
              " ('2 Hidden Layers', 'sigmoid'): 0.1244,\n",
              " ('2 Hidden Layers', 'tanh'): 0.0201,\n",
              " ('3 Hidden Layers', 'relu'): 0.34,\n",
              " ('3 Hidden Layers', 'sigmoid'): 0.0777,\n",
              " ('3 Hidden Layers', 'tanh'): 0.0302}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "configs = {\n",
        "    '1 Hidden Layer': [256],\n",
        "    '2 Hidden Layers': [256, 128],\n",
        "    '3 Hidden Layers': [256, 128, 64]\n",
        "}\n",
        "\n",
        "activations = ['relu', 'sigmoid', 'tanh']\n",
        "results = {}\n",
        "\n",
        "for name, cfg in configs.items():\n",
        "    for act in activations:\n",
        "        model = MLP(input_dim, cfg, act, num_classes)\n",
        "        f1 = train_eval(model, train_loader, test_loader)\n",
        "        results[(name, act)] = round(f1, 4)\n",
        "        print(name, act, \"Macro F1:\", round(f1, 4))\n",
        "\n",
        "results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747106e7",
      "metadata": {
        "id": "747106e7"
      },
      "source": [
        "\n",
        "## 9. Conclusion\n",
        "\n",
        "- Logistic Regression provides a linear baseline\n",
        "- Increasing hidden layers improves MLP performance\n",
        "- ReLU activation performs best\n",
        "- Sigmoid performs worst due to vanishing gradients\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}